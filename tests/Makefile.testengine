#Note1: SPECIFY TESTS_ROOT
#Note2: RELEASE VERSION OF ZEROVM REQUIRED TO PARSE TESTS RESULTS
#Note3: SET LIST VAR OF PARTICULAR TESTS WANT TO RUN, FOR SEVERAL
#TESTS USE DOUBLE QUOTES
#Given Makefile - test runner using release build of zerovm

#mount/remount tar archives
TEST_TAR=foo.tar
TEST_TAR_MOUNT=$(CURDIR)/mount.tar
TEST_TAR_REMOUNT=$(CURDIR)/remount.tar
#file for both TAR archives
TESTFILE=test.1234
OUTFILE=$(CURDIR)/$(BASENAME)

#default memory size
DEF_MEMMAX=4294967296
#default types of channels we specifying from make
DEF_CHANNEL_READONLY_TYPE=0
DEF_CHANNEL_WRITEONLY_TYPE=0
DEF_CHANNEL_READWRITE_TYPE=1
CHANNEL_READONLY=$(OUTFILE).readonly.channel
CHANNEL_WRITEONLY=$(OUTFILE).writeonly.channel
CHANNEL_READWRITE=$(OUTFILE).read-write.channel
#default size for writeonly channel
DEF_CHANNEL_WRITEONLY_SIZE=9999

OUTPUT_LAST=last_test.output
OUTPUT_FAIL=fail_tests.output
TEST_INCLUDES=$(shell find $(TESTS_ROOT) -name "*.h")
TEST_SOURCES=$(shell find $(TESTS_ROOT) -name "*.c")
TEST_OBJECTS=$(addsuffix .o, $(basename $(TEST_SOURCES) ) )
TEST_NVRAMS=$(addsuffix .nvram, $(basename $(TEST_SOURCES) ) )
TEST_MANIFESTS=$(addsuffix .manifest, $(basename $(TEST_SOURCES) ) )
TEST_STDOUTS=$(addsuffix .stdout.std, $(basename $(TEST_SOURCES) ) )
TEST_STDERRS=$(addsuffix .stderr.std, $(basename $(TEST_SOURCES) ) )
TEST_LOG_ZVM=$(addsuffix .zerovm.log, $(basename $(TEST_SOURCES) ) )
TEST_LOG_DEBUG=$(addsuffix .zrtdebug.log, $(basename $(TEST_SOURCES) ) )
TEST_TARS=$(addsuffix .$(TEST_TAR), $(basename $(TEST_SOURCES) ) )
#user can run only particular tests by specifying test names as they
#displayed at report if specifying several test use double quotes
LIST?=$(patsubst %.o, %.nexe, $(TEST_OBJECTS))
TEST_NEXES=$(LIST)
TEST_UNPARSED_TRACES=$(patsubst %.nexe, %.TRACE.unparsed, $(LIST))
TEST_TRACES=$(patsubst %.nexe, %.TRACE, $(LIST))
TEST_ALLOC_REPORTS=$(patsubst %.nexe, %.alloc, $(LIST))
TEST_HIERARCHY_TRACES=$(patsubst %.nexe, %.TRACE.hierarchy, $(LIST))
TEST_CHANNELS=$(shell find $(TESTS_ROOT) -name "*.channel")
COUNTER=0

#save failed tests to display it in report
#if string does not contain PASS, then output error
AWK_HANDLE_FAIL=awk '{\
if ( match($$0, "PASS zvmstatus") == 0 ) {\
	print testname, $$0 \
	}\
}' 

TESTBASE=
EXCL=

CFLAGS+=-g #debug
CFLAGS+=-std=gnu99
CFLAGS+=-D_GNU_SOURCE
CFLAGS+=-Wno-long-long -m64
CFLAGS+=-Werror-implicit-function-declaration
CFLAGS+=-I.. -I. -Iframework
CFLAGS+=-Iinclude
CFLAGS+=-I$(ZRT_ROOT)/lib

#For rt tests
LDFLAGS+= -lrt
#For dlopen
LDFLAGS+= -ldl
#math
LDFLAGS+= -lm
#crypt
LDFLAGS+= -lcrypt
#networking mapreduce
LDFLAGS+= -lmapreduce -lnetworking

#uncomment below one if want to display removed files list during clean
#VERBOSE_CLEAN=-v

all: prepare $(ZEROVM) $(TEST_NEXES) report

gcov: LDFLAGS+=${GCOV_LDFLAGS}
gcov: CPPFLAGS+=${GCOV_FLAGS}
gcov: CFLAGS+=${GCOV_FLAGS}
gcov: prepare $(ZEROVM) $(TEST_NEXES) report

trace: CPPFLAGS+=${TRACE_FLAGS}
trace: CFLAGS+=${TRACE_FLAGS}
trace: prepare $(ZEROVM) $(TEST_TRACES) report 
	echo "trace success, see files: *.TRACE, *.TRACE.hierarchy"

clean:
	@find -name "*.scp" | xargs rm -f $(VERBOSE_CLEAN)
	@rm -f $(VERBOSE_CLEAN) $(OUTPUT_LAST)
	@rm -f $(VERBOSE_CLEAN) $(OUTPUT_FAIL)
	@rm -f $(VERBOSE_CLEAN) $(TEST_OBJECTS)
	@rm -f $(VERBOSE_CLEAN) $(TEST_STDOUTS)
	@rm -f $(VERBOSE_CLEAN) $(TEST_STDERRS)
	@rm -f $(VERBOSE_CLEAN) $(TEST_LOG_ZVM)
	@rm -f $(VERBOSE_CLEAN) $(TEST_NEXES)
	@rm -f $(VERBOSE_CLEAN) $(TEST_MANIFESTS)
	@rm -f $(VERBOSE_CLEAN) $(TEST_NVRAMS)
	@rm -f $(VERBOSE_CLEAN) $(TEST_LOG_DEBUG)
	@rm -f $(VERBOSE_CLEAN) $(TEST_TARS)
	@rm -f $(VERBOSE_CLEAN) $(TEST_CHANNELS)
	@rm -f $(VERBOSE_CLEAN) $(TEST_TAR_MOUNT) $(TEST_TAR_REMOUNT)
	@rm -f $(VERBOSE_CLEAN) $(TEST_UNPARSED_TRACES) $(TEST_TRACES) $(TEST_HIERARCHY_TRACES)
	@rm -f $(VERBOSE_CLEAN) $(TEST_ALLOC_REPORTS) $(ALLOC_REPORT_OBJ)


prepare:
	$(eval TMPDIR:=$(shell mktemp -d))
	@echo "mount" > $(TMPDIR)/$(TESTFILE)
	@tar -cf    ${TEST_TAR_MOUNT} -C $(TMPDIR) $(TESTFILE)
	@echo "remount" > $(TMPDIR)/$(TESTFILE)
	@tar -cf ${TEST_TAR_REMOUNT} -C $(TMPDIR) ${TESTFILE}
	@rm -fr $(TMPDIR)

$(ZEROVM):
	$(error "$(ZEROVM) does not exist")


$(ALLOC_REPORT_OBJ): $(ALLOC_REPORT_SRC)
	@$(CC) -c $(ALLOC_REPORT_SRC) $(CFLAGS) -o $(ALLOC_REPORT_OBJ)

$(TEST_TRACES): $(TEST_UNPARSED_TRACES)
	@echo --------------------------------------------
	python $(TRACE_PARSER) $(basename $@).nexe $(basename $@).TRACE.unparsed

$(TEST_NEXES): $(ALLOC_REPORT_OBJ) $(TEST_SOURCES) $(TEST_INCLUDES)
#increase test counter
	$(eval COUNTER:=$(shell echo $$(($(COUNTER)+1))) )
#prrepare variables
	$(eval BASENAME:=$(basename $@))
	$(eval NAMEONLY:=$(notdir $(BASENAME)))
	$(eval SPECIFIC_TEST_FLAGS:=$(CFLAGS-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_CMDLINE:=$(CMDLINE-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_ENV:=$(ENV-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_MAPPING:=$(MAPPING-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_FSTAB:=$(FSTAB-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_PRECACHE:=$(PRECACHE-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_FORK=$(FORK-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_CHANNELS=$(CHANNELS-$(NAMEONLY).c))
#prepare variable ralated to forked session tests
	$(eval SPECIFIC_TEST_CMDLINE_FORKED:=$(CMDLINE_FORKED-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_ENV_FORKED:=$(ENV_FORKED-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_MAPPING_FORKED:=$(MAPPING_FORKED-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_FSTAB_FORKED:=$(FSTAB_FORKED-$(NAMEONLY).c))
#channels testing suport
	$(eval SPECIFIC_TEST_CHANNEL_READONLY_TYPE:=$(firstword $(CHANNEL_READONLY_TYPE-$(NAMEONLY).c) $(DEF_CHANNEL_READONLY_TYPE)))
	$(eval SPECIFIC_TEST_CHANNEL_WRITEONLY_TYPE:=$(firstword $(CHANNEL_WRITEONLY_TYPE-$(NAMEONLY).c) $(DEF_CHANNEL_WRITEONLY_TYPE)))
	$(eval SPECIFIC_TEST_CHANNEL_READWRITE_TYPE:=$(firstword $(CHANNEL_READWRITE_TYPE-$(NAMEONLY).c) $(DEF_CHANNEL_READWRITE_TYPE)))
#channels initial contents
	$(eval SPECIFIC_TEST_CHANNEL_READONLY=$(CHANNEL_READONLY_CONTENT-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_CHANNEL_WRITEONLY=$(CHANNEL_WRITEONLY_CONTENT-$(NAMEONLY).c))
	$(eval SPECIFIC_TEST_CHANNEL_READWRITE=$(CHANNEL_READWRITE_CONTENT-$(NAMEONLY).c))
#specific channel size
	$(eval SPECIFIC_TEST_CHANNEL_WRITEONLY_SIZE:=$(firstword $(CHANNEL_WRITEONLY_SIZE-$(NAMEONLY).c) $(DEF_CHANNEL_WRITEONLY_SIZE)))
#specific memory size
	$(eval SPECIFIC_TEST_MEMMAX:=$(firstword $(MEMMAX-$(NAMEONLY).c) $(DEF_MEMMAX)))
#prepare channel files
	@echo -n $(SPECIFIC_TEST_CHANNEL_READONLY) > $(CHANNEL_READONLY)
	@echo -n $(SPECIFIC_TEST_CHANNEL_WRITEONLY) > $(CHANNEL_WRITEONLY)
	@echo -n $(SPECIFIC_TEST_CHANNEL_READWRITE) > $(CHANNEL_READWRITE)
#tar mount/remount support
	$(eval SPECIFIC_TEST_MOUNT=$(CURDIR)/$(BASENAME).$(TEST_TAR))
	@echo "RUN TEST $@ "
#compile
	@$(CC) -c -o $(BASENAME).o $(CFLAGS) $(SPECIFIC_TEST_FLAGS) $(BASENAME).c
	@$(CC) -o $@ $(BASENAME).o $(LDFLAGS)
#prepare scripts for debug purposes with GDB
	@sed s@{NEXE_FULL_PATH}@$(CURDIR)/$(BASENAME).nexe@g $(ZRT_ROOT)/gdb_commands.template > $(CURDIR)/$(BASENAME).scp
#prepare manifest
	@sed s@{OUTFILE}@$(OUTFILE)@g manifest_tests.template | \
	 sed s@{ABS_PATH}@$(CURDIR)/@g | \
	 sed s@{CHANNEL_READONLY_TYPE}@$(SPECIFIC_TEST_CHANNEL_READONLY_TYPE)@g | \
	 sed s@{CHANNEL_WRITEONLY_TYPE}@$(SPECIFIC_TEST_CHANNEL_WRITEONLY_TYPE)@g | \
	 sed s@{CHANNEL_READWRITE_TYPE}@$(SPECIFIC_TEST_CHANNEL_READWRITE_TYPE)@g | \
	 sed s@{CHANNEL_WRITEONLY_SIZE}@$(SPECIFIC_TEST_CHANNEL_WRITEONLY_SIZE)@g | \
	 sed s@{GCOV_DATA_TAR}@$(GCOV_DATA_TAR)@g | \
	 sed s@{MOUNTS_PATH}@$(ZRT_ROOT)/mounts/@g | \
	 sed s@{JOB}@$(SPECIFIC_TEST_FORK)@g | \
	 sed s@{TAR_MOUNT}@$(TEST_TAR)@g | \
	 sed s@{DYNAMIC_CHANNELS_LIST}@"$(SPECIFIC_TEST_CHANNELS)"@g | \
	 sed s@{BR}@'\n'@g | \
	 sed s@{MEMMAX}@$(SPECIFIC_TEST_MEMMAX)@g > $(CURDIR)/$(BASENAME).manifest
#prepare nvram
	@sed s@{ENVIRONMENT}@"$(SPECIFIC_TEST_ENV)"@g nvram_tests.template | \
	 sed s@{MAPPING}@"$(SPECIFIC_TEST_MAPPING)"@g | \
	 sed s@{FSTAB}@"$(SPECIFIC_TEST_FSTAB)"@g | \
	 sed s@{PRECACHE}@"$(SPECIFIC_TEST_PRECACHE)"@g | \
	 sed s@{SECONDS}@"seconds=$(shell date +%s)"@g | \
	 sed s@{BR}@'\n'@g | \
	 sed s@{COMMAND_LINE}@"$(SPECIFIC_TEST_CMDLINE)"@g > $(CURDIR)/$(BASENAME).nvram
#Run test under zerovm and display returned error code
#$shell could not be used to get test result from file because it unexpectadly
#returns contents of previosly saved test output, and it is the main reason why using awk;
#parsing correct output retrieved via pipe
	@cp -f ${TEST_TAR_MOUNT} $(SPECIFIC_TEST_MOUNT);
	@$(ZEROVM) $(CURDIR)/$(BASENAME).manifest -P -v3 \
	| $(AWK_GET_ZEROVM_APP_RETURN_CODE) \
	| $(AWK_HANDLE_FAIL) testname="$@"  2>&1 | tee -a $(OUTPUT_FAIL)
#If session was forked by zfork() and socket file exist then restore forked session now
#rewrite tar image to test remount, prepare updated nvram
	@if [ "${SPECIFIC_TEST_FORK}" != "" ] && [ -S "${SPECIFIC_TEST_FORK}" ] ; then \
	rm -f ${SPECIFIC_TEST_MOUNT}; cp -f ${TEST_TAR_REMOUNT} ${SPECIFIC_TEST_MOUNT}; \
	sed s@{ENVIRONMENT}@"$(SPECIFIC_TEST_ENV_FORKED)"@g nvram_tests.template | \
	sed s@{MAPPING}@"$(SPECIFIC_TEST_MAPPING_FORKED)"@g | \
	sed s@{FSTAB}@"$(SPECIFIC_TEST_FSTAB_FORKED)"@g | \
	sed s@{PRECACHE}@"$(SPECIFIC_TEST_PRECACHE)"@g | \
	sed s@{SECONDS}@"seconds=$(shell date +%s)"@g | \
	sed s@{BR}@'\n'@g | \
	sed s@{COMMAND_LINE}@"$(SPECIFIC_TEST_CMDLINE_FORKED)"@g > $(CURDIR)/$(BASENAME).nvram;	\
	echo "RUN FORKED TEST $@ "; \
	cat $(CURDIR)/$(BASENAME).manifest \
	| python ../daemon_client.py "${SPECIFIC_TEST_FORK}" 2>&1 \
	| $(AWK_GET_ZEROVM_APP_RETURN_CODE) \
	| $(AWK_HANDLE_FAIL) testname="$@ FORK" | tee -a $(OUTPUT_FAIL) ; \
	rm -f ${SPECIFIC_TEST_FORK} ; \
	fi;

#completion of nexe rules is prerequisite for report
report: $(TEST_NEXES)
	$(eval FAILED_TESTS_COUNT:=$(shell echo `cat $(OUTPUT_FAIL) | wc -l`))
#display tests resuts
	@echo --------------------------------------------
	@echo $(COUNTER) tests was executed
	@echo -n "Failed "
	@echo -n `cat $(OUTPUT_FAIL) | wc -l`
	@echo " tests:"
	@cat $(OUTPUT_FAIL)
	@rm -f $(OUTPUT_FAIL) $(OUTPUT_LAST)
	@exit $(FAILED_TESTS_COUNT)

#$(OUTPUT_FAIL):
#has no output fail if this rule is active
#	$(error Nothing output)
